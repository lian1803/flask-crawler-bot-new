#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ìë™ í¬ë¡¤ë§ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import requests
import json
import time
from datetime import datetime

def test_crawler_endpoints():
    """í¬ë¡¤ë§ ê´€ë ¨ ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
    
    base_url = "http://localhost:5000"  # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©
    
    print("ğŸ§ª ìë™ í¬ë¡¤ë§ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    # 1. ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ í™•ì¸
    print("1ï¸âƒ£ ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ í™•ì¸")
    try:
        response = requests.get(f"{base_url}/scheduler/status")
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰ ì¤‘: {data['scheduler_running']}")
            print(f"ğŸ“‹ ë“±ë¡ëœ ì‘ì—…: {len(data['jobs'])}ê°œ")
            for job in data['jobs']:
                print(f"   - {job['name']}: {job['next_run']}")
        else:
            print(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {response.status_code}")
    except Exception as e:
        print(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {e}")
    
    print()
    
    # 2. ìˆ˜ë™ í¬ë¡¤ë§ ì‹¤í–‰
    print("2ï¸âƒ£ ìˆ˜ë™ í¬ë¡¤ë§ ì‹¤í–‰")
    try:
        response = requests.post(f"{base_url}/crawl")
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… í¬ë¡¤ë§ ì„±ê³µ: {data['message']}")
        else:
            print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {response.status_code}")
            print(f"ì‘ë‹µ: {response.text}")
    except Exception as e:
        print(f"âŒ í¬ë¡¤ë§ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
    
    print()
    
    # 3. í†µê³„ ì •ë³´ í™•ì¸
    print("3ï¸âƒ£ í†µê³„ ì •ë³´ í™•ì¸")
    try:
        response = requests.get(f"{base_url}/stats")
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… QA ë°ì´í„°: {data['qa_data_count']}ê°œ")
            print(f"âœ… ìµœê·¼ ëŒ€í™”: {data['recent_conversations']}ê°œ")
            print(f"âœ… ì„œë²„ ìƒíƒœ: {data['server_status']}")
        else:
            print(f"âŒ í†µê³„ í™•ì¸ ì‹¤íŒ¨: {response.status_code}")
    except Exception as e:
        print(f"âŒ í†µê³„ í™•ì¸ ì˜¤ë¥˜: {e}")
    
    print()
    
    # 4. í—¬ìŠ¤ ì²´í¬
    print("4ï¸âƒ£ í—¬ìŠ¤ ì²´í¬")
    try:
        response = requests.get(f"{base_url}/health")
        if response.status_code == 200:
            data = response.json()
            print(f"âœ… ì„œë²„ ìƒíƒœ: {data['status']}")
            print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤: {data['database']}")
        else:
            print(f"âŒ í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨: {response.status_code}")
    except Exception as e:
        print(f"âŒ í—¬ìŠ¤ ì²´í¬ ì˜¤ë¥˜: {e}")
    
    print()
    print("ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

def test_crawler_direct():
    """í¬ë¡¤ëŸ¬ ì§ì ‘ ì‹¤í–‰ í…ŒìŠ¤íŠ¸"""
    print("ğŸ”„ í¬ë¡¤ëŸ¬ ì§ì ‘ ì‹¤í–‰ í…ŒìŠ¤íŠ¸")
    print("=" * 30)
    
    try:
        import subprocess
        result = subprocess.run(['python', 'incremental_notice_crawler.py'], 
                              capture_output=True, text=True, timeout=60)
        
        print("ğŸ“¤ í¬ë¡¤ëŸ¬ ì¶œë ¥:")
        print(result.stdout)
        
        if result.stderr:
            print("âŒ í¬ë¡¤ëŸ¬ ì˜¤ë¥˜:")
            print(result.stderr)
        
        print(f"âœ… í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì™„ë£Œ (ì¢…ë£Œ ì½”ë“œ: {result.returncode})")
        
    except subprocess.TimeoutExpired:
        print("â° í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼ (60ì´ˆ)")
    except Exception as e:
        print(f"âŒ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    print("ğŸš€ ìë™ í¬ë¡¤ë§ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print(f"â° í…ŒìŠ¤íŠ¸ ì‹œì‘ ì‹œê°„: {datetime.now()}")
    print()
    
    # 1. í¬ë¡¤ëŸ¬ ì§ì ‘ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
    test_crawler_direct()
    print()
    
    # 2. ì›¹ ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸ (ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¼ ë•Œë§Œ)
    try:
        test_crawler_endpoints()
    except requests.exceptions.ConnectionError:
        print("âš ï¸  ì„œë²„ê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•„ ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        print("   ì„œë²„ë¥¼ ë¨¼ì € ì‹¤í–‰í•œ í›„ ë‹¤ì‹œ í…ŒìŠ¤íŠ¸í•´ì£¼ì„¸ìš”.")
    
    print()
    print("ğŸ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!") 