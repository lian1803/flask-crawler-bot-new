import json
import openai
import requests
from datetime import datetime
from transformers import GPT2Tokenizer
from config import openai_model, temperature, max_tokens, bot_name
from database import SchoolDatabase
from utils import (
    is_meal_related, is_notice_related, is_greeting, 
    extract_date_from_text, format_meal_info, format_notice_info
)

# GPT2 í† í¬ë‚˜ì´ì € ì´ˆê¸°í™”
tokenizer = GPT2Tokenizer.from_pretrained("gpt2")

class SchoolBotLogic:
    def __init__(self):
        self.db = SchoolDatabase()
        self.conversations = {}
        self.max_conversation_length = 10
        
        # OpenAI ì„¤ì •
        openai.api_key = openai.api_key
        
    def count_tokens(self, text):
        """í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        return len(tokenizer.encode(text, truncation=True))
    
    def load_conversation_history(self, user_id):
        """ì‚¬ìš©ìì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        if user_id not in self.conversations:
            self.conversations[user_id] = []
        return self.conversations[user_id]
    
    def save_conversation(self, user_id, user_message, bot_response):
        """ëŒ€í™”ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        if user_id not in self.conversations:
            self.conversations[user_id] = []
        
        self.conversations[user_id].append({
            "user": user_message,
            "bot": bot_response,
            "timestamp": datetime.now().isoformat()
        })
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ê¸¸ì´ ì œí•œ
        if len(self.conversations[user_id]) > self.max_conversation_length:
            self.conversations[user_id] = self.conversations[user_id][-self.max_conversation_length:]
    
    def read_prompt(self):
        """í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì½ìŠµë‹ˆë‹¤."""
        try:
            with open("logic/prompt.txt", "r", encoding="utf-8") as f:
                return f.read()
        except FileNotFoundError:
            return "ë‹¹ì‹ ì€ íŒŒì£¼ì™€ì„ì´ˆë“±í•™êµì˜ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤."
    
    def create_system_message(self, user_id):
        """ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        prompt = self.read_prompt()
        
        # í•™êµ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ ì¶”ê°€
        qa_data = self.db.get_all_qa_data()
        if qa_data:
            qa_context = "\n\n## í•™êµ QA ë°ì´í„°ë² ì´ìŠ¤:\n"
            for qa in qa_data[:10]:  # ìµœëŒ€ 10ê°œë§Œ í¬í•¨
                qa_context += f"Q: {qa['question']}\nA: {qa['answer']}\n\n"
            prompt += qa_context
        
        return prompt
    
    def handle_meal_request(self, user_message):
        """ê¸‰ì‹ ê´€ë ¨ ìš”ì²­ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        date = extract_date_from_text(user_message)
        meal_info = self.db.get_meal_info(date)
        return format_meal_info(meal_info)
    
    def handle_notice_request(self, user_message):
        """ê³µì§€ì‚¬í•­ ê´€ë ¨ ìš”ì²­ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        notices = self.db.get_latest_notices(5)
        return format_notice_info(notices)
    
    def handle_qa_request(self, user_message):
        """QA ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë‹µë³€ì„ ì°¾ìŠµë‹ˆë‹¤."""
        # ì •í™•í•œ ë§¤ì¹­ ì‹œë„
        qa_result = self.db.search_qa_data(user_message)
        if qa_result:
            answer = qa_result["answer"]
            if qa_result.get("additional_answer"):
                answer += f"\n\n{qa_result['additional_answer']}"
            return answer
        
        # í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹œë„
        keywords = self.extract_keywords(user_message)
        for keyword in keywords:
            qa_results = self.db.search_qa_by_keyword(keyword, 3)
            if qa_results:
                # ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë‹µë³€ ì„ íƒ
                return qa_results[0]["answer"]
        
        return None
    
    def extract_keywords(self, text):
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (í•œê¸€ ë‹¨ì–´, 2ê¸€ì ì´ìƒ)
        import re
        keywords = re.findall(r'[ê°€-í£]{2,}', text)
        return keywords[:5]  # ìµœëŒ€ 5ê°œ í‚¤ì›Œë“œ
    
    def generate_ai_response(self, user_message, user_id):
        """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¡œë“œ
            conversation_history = self.load_conversation_history(user_id)
            
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ìƒì„±
            system_message = self.create_system_message(user_id)
            
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [{"role": "system", "content": system_message}]
            
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€
            for conv in conversation_history[-6:]:  # ìµœê·¼ 6ê°œ ëŒ€í™”ë§Œ í¬í•¨
                messages.append({"role": "user", "content": conv["user"]})
                messages.append({"role": "assistant", "content": conv["bot"]})
            
            # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            messages.append({"role": "user", "content": user_message})
            
            # í† í° ìˆ˜ í™•ì¸ ë° ì¡°ì •
            total_tokens = sum(self.count_tokens(msg["content"]) for msg in messages)
            if total_tokens > 3000:  # í† í° ì œí•œ
                # ê°€ì¥ ì˜¤ë˜ëœ ë©”ì‹œì§€ë“¤ ì œê±°
                while total_tokens > 3000 and len(messages) > 3:
                    removed_tokens = self.count_tokens(messages[1]["content"]) + self.count_tokens(messages[2]["content"])
                    messages.pop(1)  # user message
                    messages.pop(1)  # assistant message
                    total_tokens -= removed_tokens
            
            # OpenAI API í˜¸ì¶œ
            response = openai.ChatCompletion.create(
                model=openai_model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    def process_message(self, user_message, user_id):
        """ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê³  ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        print(f"ì‚¬ìš©ì {user_id}: {user_message}")
        
        # 1. ì¸ì‚¬ë§ ì²˜ë¦¬
        if is_greeting(user_message):
            response = f"ì•ˆë…•í•˜ì„¸ìš”! {bot_name}ì…ë‹ˆë‹¤. ğŸ˜Š\n\në¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n\nâ€¢ ì˜¤ëŠ˜ ê¸‰ì‹ ë©”ë‰´\nâ€¢ ìµœì‹  ê³µì§€ì‚¬í•­\nâ€¢ í•™êµ ê´€ë ¨ ì§ˆë¬¸"
            self.save_conversation(user_id, user_message, response)
            return response
        
        # 2. ê¸‰ì‹ ê´€ë ¨ ìš”ì²­ ì²˜ë¦¬
        if is_meal_related(user_message):
            response = self.handle_meal_request(user_message)
            self.save_conversation(user_id, user_message, response)
            return response
        
        # 3. ê³µì§€ì‚¬í•­ ê´€ë ¨ ìš”ì²­ ì²˜ë¦¬
        if is_notice_related(user_message):
            response = self.handle_notice_request(user_message)
            self.save_conversation(user_id, user_message, response)
            return response
        
        # 4. QA ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë‹µë³€ ì°¾ê¸°
        qa_response = self.handle_qa_request(user_message)
        if qa_response:
            self.save_conversation(user_id, user_message, qa_response)
            return qa_response
        
        # 5. AIë¥¼ ì‚¬ìš©í•œ ë‹µë³€ ìƒì„±
        ai_response = self.generate_ai_response(user_message, user_id)
        self.save_conversation(user_id, user_message, ai_response)
        return ai_response
    
    def get_conversation_summary(self, user_id):
        """ì‚¬ìš©ìì˜ ëŒ€í™” ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤."""
        if user_id not in self.conversations:
            return "ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
        
        conversations = self.conversations[user_id]
        if not conversations:
            return "ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
        
        summary = f"ğŸ“ ìµœê·¼ ëŒ€í™” ê¸°ë¡ ({len(conversations)}ê°œ)\n\n"
        for i, conv in enumerate(conversations[-5:], 1):  # ìµœê·¼ 5ê°œë§Œ
            summary += f"{i}. Q: {conv['user'][:30]}...\n"
            summary += f"   A: {conv['bot'][:50]}...\n\n"
        
        return summary 