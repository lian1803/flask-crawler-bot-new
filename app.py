from flask import Flask, request, jsonify
import sqlite3
import json
import os
from datetime import datetime, timedelta
import re
from openai import OpenAI
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

app = Flask(__name__)

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
def init_db():
    conn = sqlite3.connect('school_data.db')
    cursor = conn.cursor()
    
    # ê³µì§€ì‚¬í•­ í…Œì´ë¸”
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS notices (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            title TEXT NOT NULL,
            content TEXT,
            url TEXT,
            created_at TEXT,
            tags TEXT,
            category TEXT
        )
    ''')
    
    # ì‹ë‹¨ í…Œì´ë¸”
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS meals (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            date TEXT NOT NULL,
            meal_type TEXT,
            menu TEXT,
            image_url TEXT
        )
    ''')
    
    # QA ë°ì´í„° í…Œì´ë¸” (ì´ë¯¸ ìƒì„±ë˜ì–´ ìˆìŒ)
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS qa_data (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            question TEXT NOT NULL,
            answer TEXT NOT NULL,
            additional_answer TEXT,
            category TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    conn.commit()
    conn.close()

def get_target_date(text):
    """ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ë‚ ì§œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    today = datetime.now()
    if "ì˜¤ëŠ˜" in text:
        return today.strftime("%Y-%m-%d")
    if "ë‚´ì¼" in text:
        return (today + timedelta(days=1)).strftime("%Y-%m-%d")
    if "ì–´ì œ" in text:
        return (today - timedelta(days=1)).strftime("%Y-%m-%d")
    if "ëª¨ë ˆ" in text:
        return (today + timedelta(days=2)).strftime("%Y-%m-%d")
    
    # "5ì›” 20ì¼", "5/20" ê°™ì€ íŒ¨í„´ ì°¾ê¸°
    match = re.search(r'(\d{1,2})[ì›”/\s](\d{1,2})ì¼?', text)
    if match:
        month, day = map(int, match.groups())
        # ì˜¬í•´ ë‚ ì§œë¡œ ê°€ì •
        return today.replace(month=month, day=day).strftime("%Y-%m-%d")
        
    return None

def get_meal_info(date):
    """íŠ¹ì • ë‚ ì§œì˜ ì‹ë‹¨ ì •ë³´ë¥¼ DBì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    conn = sqlite3.connect('school_data.db')
    cursor = conn.cursor()
    cursor.execute('SELECT menu FROM meals WHERE date = ? AND meal_type = "ì¤‘ì‹"', (date,))
    result = cursor.fetchone()
    conn.close()
    if result and result[0]:
        return f"{date} ì¤‘ì‹ ë©”ë‰´ì…ë‹ˆë‹¤:\n\n{result[0]}"
    return f"{date}ì—ëŠ” ì‹ë‹¨ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."

def get_latest_notices():
    """ìµœì‹  ê³µì§€ì‚¬í•­ 5ê°œë¥¼ DBì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    conn = sqlite3.connect('school_data.db')
    cursor = conn.cursor()
    cursor.execute('SELECT title, created_at FROM notices ORDER BY created_at DESC LIMIT 5')
    results = cursor.fetchall()
    conn.close()
    if results:
        response = "ìµœê·¼ ê³µì§€ì‚¬í•­ 5ê°œì…ë‹ˆë‹¤:\n\n"
        for title, created_at in results:
            response += f"â€¢ {title} ({created_at})\n"
        return response
    return "í˜„ì¬ ë“±ë¡ëœ ê³µì§€ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤."

def classify_question_category(user_message):
    """ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì¹´í…Œê³ ë¦¬(ì´ˆë“±/ìœ ì¹˜ì›/ì²¨ë¶€ì‚¬ì§„)ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤."""
    user_message_lower = user_message.lower()
    
    # ì´ˆë“±í•™êµ ê´€ë ¨ í‚¤ì›Œë“œ
    elementary_keywords = [
        'ì´ˆë“±', 'ì´ˆë“±í•™êµ', 'í•™ë…„', 'êµê³¼ì„œ', 'ë°©ê³¼í›„', 'ê¸‰ì‹', 'í•™ì‚¬ì¼ì •', 
        'ì „ì…', 'ì „ì¶œ', 'ê²°ì„', 'ì²´í—˜í•™ìŠµ', 'í•™êµì¥', 'ë‹´ì„', 'ì„ ìƒë‹˜',
        'í•™ìƒ', 'êµì‹¤', 'ë°˜', 'ìˆ˜ì—…', 'í•˜êµ', 'ë“±êµ', 'ë²„ìŠ¤', 'ëŠ˜ë´„',
        'ëŒë´„', 'ë°©ê³¼í›„í•™êµ', 'í•™êµí­ë ¥', 'ì¬í•™ì¦ëª…ì„œ', 'ìƒí™œê¸°ë¡ë¶€'
    ]
    
    # ìœ ì¹˜ì› ê´€ë ¨ í‚¤ì›Œë“œ
    kindergarten_keywords = [
        'ìœ ì¹˜ì›', 'ìœ ì•„', 'í•˜ì›', 'ì›ì¥', 'êµì‚¬', 'ë©´ë‹´', 'êµìœ¡ë¹„',
        'ìˆ˜ë‹´ê¸ˆ', 'í•™ë¹„', 'íŠ¹ìˆ˜í•™ê¸‰', 'í˜„ì¥í•™ìŠµ', 'íŠ¹ì„±í™”', 'í•™ë¶€ëª¨',
        'ì°¸ì—¬ìˆ˜ì—…', 'ìœ ì¹˜ì›ë³µ', 'ì£¼ì •ì°¨', 'í•™ì›ì„ ìƒë‹˜', 'ëŒ€ê¸°ì',
        'ìœ ì•„ëª¨ì§‘', 'ì…í•™ì„¤ëª…íšŒ', 'ì˜ˆë¹„ì†Œì§‘'
    ]
    
    # ì²¨ë¶€ì‚¬ì§„ ê´€ë ¨ í‚¤ì›Œë“œ
    attachment_keywords = [
        'ì‚¬ì§„', 'íŒŒì¼', 'ì²¨ë¶€', 'ì–‘ì‹', 'ì„œë¥˜', 'ì‹ ê³ ì„œ', 'ë³´ê³ ì„œ',
        'ì‹ ì²­ì„œ', 'í™•ì¸ì„œ', 'ì¦ëª…ì„œ', 'ê³„íšì„œ', 'ì‹œê°„í‘œ', 'ì¼ì •í‘œ'
    ]
    
    # ì ìˆ˜ ê³„ì‚°
    elementary_score = sum(1 for keyword in elementary_keywords if keyword in user_message_lower)
    kindergarten_score = sum(1 for keyword in kindergarten_keywords if keyword in user_message_lower)
    attachment_score = sum(1 for keyword in attachment_keywords if keyword in user_message_lower)
    
    # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì¹´í…Œê³ ë¦¬ ë°˜í™˜
    scores = {
        'ì´ˆë“±': elementary_score,
        'ìœ ì¹˜ì›': kindergarten_score,
        'ì²¨ë¶€ ì‚¬ì§„ íŒŒì¼': attachment_score
    }
    
    max_score = max(scores.values())
    if max_score > 0:
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì¹´í…Œê³ ë¦¬ë“¤ ì¤‘ì—ì„œ ì„ íƒ
        max_categories = [cat for cat, score in scores.items() if score == max_score]
        return max_categories[0]  # ì²« ë²ˆì§¸ ì¹´í…Œê³ ë¦¬ ë°˜í™˜
    
    return None  # ë¶„ë¥˜ ë¶ˆê°€ëŠ¥

def normalize_text(text):
    """í…ìŠ¤íŠ¸ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤ (ë™ì˜ì–´ ì²˜ë¦¬ í¬í•¨)"""
    if not text:
        return ""
    
    text_lower = text.lower()
    
    # ë™ì˜ì–´ ì‚¬ì „
    synonyms = {
        "ë°©ê³¼í›„": ["ë°©ê³¼í›„í•™êµ", "ë°©ê³¼í›„ ê³¼ì •", "ë°©ê³¼í›„ í”„ë¡œê·¸ë¨"],
        "ê¸‰ì‹": ["ì‹ë‹¨", "ë©”ë‰´", "ë°¥", "ì ì‹¬", "ì¤‘ì‹"],
        "í•™ì‚¬ì¼ì •": ["ì‹œì •í‘œ", "ì¼ì •", "í•™ì‚¬", "í•™ì‚¬ì¼ì •í‘œ"],
        "êµê³¼ì„œ": ["êµê³¼ì„œ", "êµì¬", "ì±…"],
        "ë‹´ì„": ["ë‹´ì„ì„ ìƒë‹˜", "ë‹´ì„êµì‚¬", "ë‹´ì„"],
        "ì „ì…": ["ì „í•™", "ì „ì…", "ì…í•™"],
        "ì „ì¶œ": ["ì „í•™", "ì „ì¶œ", "ì¡¸ì—…"],
        "ê²°ì„": ["ê²°ì„", "íœ´ê°€", "ë³‘ê°€"],
        "ì²´í—˜í•™ìŠµ": ["ì²´í—˜í•™ìŠµ", "í˜„ì¥í•™ìŠµ", "ê²¬í•™"],
        "ì¬í•™ì¦ëª…ì„œ": ["ì¬í•™ì¦ëª…ì„œ", "ì¬í•™ì¦ëª…", "ì¦ëª…ì„œ"],
        "ìƒí™œê¸°ë¡ë¶€": ["ìƒí™œê¸°ë¡ë¶€", "ìƒí™œê¸°ë¡", "ê¸°ë¡ë¶€"]
    }
    
    # ë™ì˜ì–´ ë³€í™˜
    normalized_text = text_lower
    for main_word, synonym_list in synonyms.items():
        for synonym in synonym_list:
            if synonym in normalized_text:
                normalized_text = normalized_text.replace(synonym, main_word)
    
    return normalized_text

def analyze_intent(user_message):
    """ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤"""
    normalized_message = normalize_text(user_message)
    
    # ì˜ë„ë³„ í‚¤ì›Œë“œ
    intent_keywords = {
        "ì‹œê°„_ë¬¸ì˜": ["ì–¸ì œ", "ëª‡ì‹œ", "ì‹œê°„", "ëë‚˜", "ì‹œì‘", "ê°œí•™", "ë°©í•™", "í•˜êµ", "ë“±êµ"],
        "ì¥ì†Œ_ë¬¸ì˜": ["ì–´ë””", "ìœ„ì¹˜", "ì¥ì†Œ", "ë³´ê´€í•¨", "êµì‹¤", "ë°˜", "í–‰ì •ì‹¤"],
        "ì ˆì°¨_ë¬¸ì˜": ["ì–´ë–»ê²Œ", "ì ˆì°¨", "ì‹ ì²­", "ë°œê¸‰", "ì—°ë½", "ìƒë‹´", "ì‹ ê³ "],
        "ì •ë³´_ë¬¸ì˜": ["ë­", "ë¬´ì—‡", "ì–¼ë§ˆ", "ëª‡", "ì •ë³´", "ì•Œê³ ", "ê¶ê¸ˆ"]
    }
    
    intent_scores = {}
    for intent, keywords in intent_keywords.items():
        score = sum(1 for keyword in keywords if keyword in normalized_message)
        intent_scores[intent] = score
    
    # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì˜ë„ ë°˜í™˜
    if intent_scores:
        max_intent = max(intent_scores, key=intent_scores.get)
        if intent_scores[max_intent] > 0:
            return max_intent
    
    return "ì¼ë°˜_ë¬¸ì˜"

def calculate_answer_relevance(question, answer, user_intent):
    """ë‹µë³€ì˜ ê´€ë ¨ì„±ì„ ê³„ì‚°í•©ë‹ˆë‹¤"""
    relevance_score = 0
    
    # ì˜ë„ë³„ ê°€ì¤‘ì¹˜
    intent_weights = {
        "ì‹œê°„_ë¬¸ì˜": 5,
        "ì¥ì†Œ_ë¬¸ì˜": 4, 
        "ì ˆì°¨_ë¬¸ì˜": 3,
        "ì •ë³´_ë¬¸ì˜": 2,
        "ì¼ë°˜_ë¬¸ì˜": 1
    }
    
    # ê¸°ë³¸ ì ìˆ˜
    relevance_score += intent_weights.get(user_intent, 1)
    
    # ë‹µë³€ì˜ êµ¬ì²´ì„± ì ìˆ˜
    if any(word in answer for word in ["ì‹œ", "ë¶„", "ì¼", "ì›”", "ë…„"]):
        relevance_score += 2  # ì‹œê°„ ì •ë³´ê°€ ìˆìœ¼ë©´ +2
    if any(word in answer for word in ["ìœ„ì¹˜", "ì¥ì†Œ", "ì–´ë””", "êµì‹¤", "ë°˜"]):
        relevance_score += 2  # ì¥ì†Œ ì •ë³´ê°€ ìˆìœ¼ë©´ +2
    if any(word in answer for word in ["ì ˆì°¨", "ì‹ ì²­", "ë°œê¸‰", "ì—°ë½"]):
        relevance_score += 2  # ì ˆì°¨ ì •ë³´ê°€ ìˆìœ¼ë©´ +2
    if "ë§í¬" in answer or "http" in answer:
        relevance_score += 1  # ë§í¬ê°€ ìˆìœ¼ë©´ +1
    
    return relevance_score

def find_qa_match_smart(user_message, preferred_category=None):
    """ë˜‘ë˜‘í•œ QA ë§¤ì¹­ (ë™ì˜ì–´ ì²˜ë¦¬ + ì˜ë„ ë¶„ì„ + ê´€ë ¨ì„± ì ìˆ˜)"""
    conn = sqlite3.connect('school_data.db')
    cursor = conn.cursor()
    
    # ëª¨ë“  QA ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    cursor.execute('SELECT question, answer, additional_answer, category FROM qa_data')
    qa_data = cursor.fetchall()
    conn.close()
    
    # ì‚¬ìš©ì ì˜ë„ ë¶„ì„
    user_intent = analyze_intent(user_message)
    normalized_user_message = normalize_text(user_message)
    
    best_match = None
    best_score = 0
    
    for question, answer, additional_answer, category in qa_data:
        score = 0
        
        # 1. ì •ê·œí™”ëœ í…ìŠ¤íŠ¸ë¡œ í‚¤ì›Œë“œ ë§¤ì¹­
        normalized_question = normalize_text(question)
        user_words = set(normalized_user_message.split())
        qa_words = set(normalized_question.split())
        
        # ê³µí†µ ë‹¨ì–´ ìˆ˜ ê³„ì‚°
        common_words = user_words.intersection(qa_words)
        score += len(common_words) * 2  # ê°€ì¤‘ì¹˜ ì¦ê°€
        
        # 2. ì¤‘ìš” í‚¤ì›Œë“œ ë§¤ì¹­ (ê°€ì¤‘ì¹˜ ë¶€ì—¬)
        important_keywords = ['í•™ë…„', 'ëë‚˜', 'ë°©ê³¼í›„', 'ì‹œì •í‘œ', 'ê¸‰ì‹', 'ê³µì§€', 'ì¼ì •', 'ì‹œê°„', 'ì–´ë””', 'ì–¸ì œ', 'ì–´ë–»ê²Œ']
        for keyword in important_keywords:
            if keyword in normalized_user_message and keyword in normalized_question:
                score += 3
        
        # 3. ì„ í˜¸ ì¹´í…Œê³ ë¦¬ ê°€ì¤‘ì¹˜
        if preferred_category and category == preferred_category:
            score += 3
        
        # 4. ë‹µë³€ ê´€ë ¨ì„± ì ìˆ˜
        relevance_score = calculate_answer_relevance(question, answer, user_intent)
        score += relevance_score
        
        # 5. ì •í™•í•œ ë§¤ì¹­ ë³´ë„ˆìŠ¤
        if any(word in normalized_user_message for word in normalized_question.split()):
            score += 5
        
        if score > best_score:
            best_score = score
            best_match = (question, answer, additional_answer, category, score)
    
    # ìµœì†Œ ì ìˆ˜ ì´ìƒì¼ ë•Œë§Œ ë§¤ì¹­ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
    if best_score >= 3:  # ì„ê³„ê°’ ìƒí–¥ ì¡°ì •
        return best_match
    return None

def search_detailed_info(keyword):
    """í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ notices í…Œì´ë¸”ì—ì„œ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    conn = sqlite3.connect('school_data.db')
    cursor = conn.cursor()
    
    # í‚¤ì›Œë“œë¡œ ê³µì§€ì‚¬í•­ ê²€ìƒ‰
    cursor.execute('''
        SELECT title, content FROM notices 
        WHERE title LIKE ? OR content LIKE ?
        ORDER BY created_at DESC LIMIT 3
    ''', (f'%{keyword}%', f'%{keyword}%'))
    
    results = cursor.fetchall()
    conn.close()
    
    if results:
        detailed_info = f"ê´€ë ¨ ìƒì„¸ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n"
        for title, content in results:
            detailed_info += f"ğŸ“‹ {title}\n"
            if content:
                # ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ í‘œì‹œ
                content_preview = content[:200] + "..." if len(content) > 200 else content
                detailed_info += f"{content_preview}\n"
            detailed_info += "\n"
        return detailed_info
    return None

# --- OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ---
api_key = os.environ.get('OPENAI_API_KEY')
if not api_key:
    print("ê²½ê³ : OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
client = OpenAI(api_key=api_key)

def get_all_data_for_ai():
    """DBì—ì„œ ëª¨ë“  ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (AIì—ê²Œ ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µ)"""
    conn = sqlite3.connect('school_data.db')
    cursor = conn.cursor()
    # ìµœê·¼ ì‹ë‹¨ 5ê°œ
    cursor.execute('SELECT date, menu FROM meals ORDER BY date DESC LIMIT 5')
    meals = cursor.fetchall()
    # ìµœê·¼ ê³µì§€ì‚¬í•­ 5ê°œ
    cursor.execute('SELECT title, created_at, content FROM notices ORDER BY created_at DESC LIMIT 5')
    notices = cursor.fetchall()
    conn.close()
    context = "### íŒŒì£¼ì™€ì„ì´ˆë“±í•™êµ ì •ë³´ ###\n\n"
    context += "--- ìµœì‹  ì‹ë‹¨ (5ê°œ) ---\n"
    for date, menu in meals:
        context += f"ë‚ ì§œ: {date}\në©”ë‰´: {menu}\n\n"
    context += "\n--- ìµœì‹  ê³µì§€ì‚¬í•­ (5ê°œ) ---\n"
    for title, created_at, content in notices:
        context += f"ë‚ ì§œ: {created_at}\nì œëª©: {title}\në‚´ìš©: {content[:100]}...\n\n" # ë‚´ìš©ì€ 100ìë§Œ
    return context

def analyze_with_ai(user_message):
    """DB ì •ë³´ë§Œ ì‚¬ìš©, í•™ë¶€ëª¨ ì•ˆë‚´ í†¤ìœ¼ë¡œ ë‹µë³€í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ ê°•í™”"""
    try:
        data_context = get_all_data_for_ai()
        system_prompt = f"""
        ë‹¹ì‹ ì€ íŒŒì£¼ì™€ì„ì´ˆë“±í•™êµì˜ ì±—ë´‡ì…ë‹ˆë‹¤.
        ì•„ë˜ì— ì œê³µë˜ëŠ” ì‹¤ì œ í•™êµ DB(ì—‘ì…€) ì •ë³´ë§Œì„ ì‚¬ìš©í•´ì„œ, ë°˜ë“œì‹œ í•™ë¶€ëª¨ë‹˜ê»˜ ì•ˆë‚´í•˜ë“¯ ë‹µë³€í•˜ì„¸ìš”.
        DBì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ë¡œ ì§€ì–´ë‚´ì§€ ë§ê³ , 'í•´ë‹¹ ì •ë³´ëŠ” í•™êµë¡œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”.'ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
        ë‹µë³€ì€ í•­ìƒ í•™ë¶€ëª¨ë‹˜ê»˜ ì•ˆë‚´í•˜ëŠ” ë§íˆ¬ë¡œ, ì¹œì ˆí•˜ê³  ê³µì†í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
        --- ì œê³µëœ ë°ì´í„° ---
        {data_context}
        --------------------
        """
        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            temperature=0.2,
        )
        answer = completion.choices[0].message.content
        return answer
    except Exception as e:
        print(f"OpenAI API ì˜¤ë¥˜: {str(e)}")
        return None

def extract_url(text):
    """í…ìŠ¤íŠ¸ì—ì„œ URL ì¶”ì¶œ"""
    if not text:
        return None
    url_pattern = r'(https?://[\w\-\.\?&=/%#]+)'
    match = re.search(url_pattern, text)
    if match:
        return match.group(1)
    return None

def is_greeting_or_smalltalk(user_message):
    """ì¸ì‚¬/ì¡ë‹´ ì—¬ë¶€ íŒë³„"""
    greetings = [
        'ì•ˆë…•', 'ì•ˆë…•í•˜ì„¸ìš”', 'ë°˜ê°€ì›Œ', 'ã…ã…‡', 'hello', 'hi', 'í•˜ì´', 'ê³ ë§ˆì›Œ', 'ê°ì‚¬', 'ìˆ˜ê³ ', 'ì˜ ë¶€íƒ', 'í—¬ë¡œ', 'êµ¿ëª¨ë‹', 'êµ¿ë°¤', 'ì˜ì', 'ì˜ ì§€ë‚´', 'ì¢‹ì€ í•˜ë£¨', 'ì¢‹ì€ ì•„ì¹¨', 'ìˆ˜ê³ í•˜ì„¸ìš”', 'ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤'
    ]
    msg = user_message.lower().replace(' ', '')
    return any(greet in msg for greet in greetings)

def get_exact_match_from_db(user_message):
    """DBì—ì„œ ì§ˆë¬¸ì´ ì™„ì „íˆ ì¼ì¹˜í•˜ëŠ” ë‹µë³€ì„ ì°¾ìŒ"""
    conn = sqlite3.connect('school_data.db')
    cursor = conn.cursor()
    cursor.execute('SELECT answer, additional_answer FROM qa_data WHERE question = ?', (user_message,))
    result = cursor.fetchone()
    conn.close()
    if result:
        answer, additional_answer = result
        if additional_answer:
            return f"{answer}\n\nì¶”ê°€ ì •ë³´: {additional_answer}"
        return answer
    return None

def find_link_answer_by_keyword(user_message):
    """ì§ˆë¬¸ì— í¬í•¨ëœ ì£¼ìš” í‚¤ì›Œë“œê°€ ë“¤ì–´ê°„ DB ì§ˆë¬¸ì„ ì°¾ì•„, ë§í¬ê°€ ìˆìœ¼ë©´ ì•ˆë‚´"""
    keywords = [w for w in user_message.replace('?', '').replace('!', '').split() if len(w) > 1]
    if not keywords:
        return None
    conn = sqlite3.connect('school_data.db')
    cursor = conn.cursor()
    # ë¶€ë¶„ì¼ì¹˜ ê²€ìƒ‰ (ì§ˆë¬¸ì— í‚¤ì›Œë“œê°€ í¬í•¨ëœ qa_data)
    for keyword in keywords:
        cursor.execute('SELECT answer, additional_answer FROM qa_data WHERE question LIKE ?', (f'%{keyword}%',))
        for answer, additional_answer in cursor.fetchall():
            url = extract_url(answer) or extract_url(additional_answer)
            if url:
                conn.close()
                return f"ê´€ë ¨ ì•ˆë‚´ëŠ” ì•„ë˜ ë§í¬ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n{url}"
    conn.close()
    return None

# ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸(í™•ì¥ ê°€ëŠ¥)
STOPWORDS = set(['ìš°ë¦¬', 'ì €í¬', 'ì• ë“¤', 'ì •ë³´', 'í•™êµ', 'ë¬¸ì˜', 'ê´€ë ¨', 'ìˆë‚˜ìš”', 'ìˆì„ê¹Œìš”', 'ì•Œë ¤ì¤˜', 'ì•Œë ¤ì£¼ì„¸ìš”', 'ì¢€', 'ì–´ë–»ê²Œ', 'ë¬´ì—‡', 'ë­', 'ì–´ë””', 'ì–¸ì œ', 'ëˆ„êµ¬', 'ì™œ', 'ëª‡', 'ê°€ìš”', 'ì¸ê°€ìš”', 'ìš”'])

def extract_nouns(text):
    # konlpy ì—†ì´ í•œê¸€/ì˜ë¬¸ ë‹¨ì–´ë§Œ ì¶”ì¶œ (2ê¸€ì ì´ìƒ, ë¶ˆìš©ì–´ ì œê±°)
    words = re.findall(r'[ê°€-í£a-zA-Z]{2,}', text)
    return [w for w in words if w not in STOPWORDS]

def find_best_link_answer(user_message):
    """ëª…ì‚¬ ì¶”ì¶œ+ë¶ˆìš©ì–´ ì œê±° í›„, DB ì§ˆë¬¸ê³¼ ë¶€ë¶„ì¼ì¹˜/ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ë§í¬ ì•ˆë‚´"""
    user_nouns = extract_nouns(user_message)
    if not user_nouns:
        return None
    conn = sqlite3.connect('school_data.db')
    cursor = conn.cursor()
    cursor.execute('SELECT question, answer, additional_answer FROM qa_data')
    qa_rows = cursor.fetchall()
    conn.close()
    # 1. ëª…ì‚¬ í¬í•¨ ë¶€ë¶„ì¼ì¹˜ í›„ë³´
    candidates = []
    for q, a, add in qa_rows:
        q_nouns = extract_nouns(q)
        if any(n in q_nouns for n in user_nouns):
            url = extract_url(a) or extract_url(add)
            candidates.append((q, a, add, url))
    # 2. ë§í¬ê°€ ìˆëŠ” í›„ë³´ ìš°ì„ 
    for q, a, add, url in candidates:
        if url:
            return f"ê´€ë ¨ ì•ˆë‚´ëŠ” ì•„ë˜ ë§í¬ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n{url}"
    # 3. í›„ë³´ê°€ ì—¬ëŸ¬ ê°œë©´ ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ê°€ê¹Œìš´ ì§ˆë¬¸ì˜ ë‹µë³€ ì•ˆë‚´
    if candidates:
        questions = [q for q, _, _, _ in candidates]
        user_texts = [user_message] + questions
        vectorizer = TfidfVectorizer().fit(user_texts)
        user_vec = vectorizer.transform([user_message])
        qa_vecs = vectorizer.transform(questions)
        sims = cosine_similarity(user_vec, qa_vecs)[0]
        best_idx = sims.argmax()
        best_q, best_a, best_add, _ = candidates[best_idx]
        if best_add:
            return f"{best_a}\n\nì¶”ê°€ ì •ë³´: {best_add}"
        return best_a
    return None

def handle_request(user_message):
    """ëª…ì‚¬ ì¶”ì¶œ+ìœ ì‚¬ë„ ê¸°ë°˜: ì¸ì‚¬/ì¡ë‹´, DB ì™„ì „ì¼ì¹˜, ëª…ì‚¬/ìœ ì‚¬ë„ ê¸°ë°˜, AI, í´ë°±"""
    # 1. ì¸ì‚¬/ì¡ë‹´ í•„í„°
    if is_greeting_or_smalltalk(user_message):
        return "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"

    # 2. DB ì™„ì „ì¼ì¹˜ ë‹µë³€ (ë§í¬ ìš°ì„ )
    conn = sqlite3.connect('school_data.db')
    cursor = conn.cursor()
    cursor.execute('SELECT answer, additional_answer FROM qa_data WHERE question = ?', (user_message,))
    result = cursor.fetchone()
    conn.close()
    if result:
        answer, additional_answer = result
        url = extract_url(answer) or extract_url(additional_answer)
        if url:
            return f"ê´€ë ¨ ì•ˆë‚´ëŠ” ì•„ë˜ ë§í¬ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n{url}"
        if additional_answer:
            return f"{answer}\n\nì¶”ê°€ ì •ë³´: {additional_answer}"
        return answer

    # 3. ëª…ì‚¬ ì¶”ì¶œ+ìœ ì‚¬ë„ ê¸°ë°˜ DB ë§¤ì¹­ (ë§í¬ ìš°ì„ )
    best_link_answer = find_best_link_answer(user_message)
    if best_link_answer:
        return best_link_answer

    # 4. AIì—ê²Œ DB ì „ì²´ ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ ì§ˆë¬¸ ì „ë‹¬
    print("INFO: AIì—ê²Œ ì§ˆë¬¸ ì „ë‹¬ (DB ì»¨í…ìŠ¤íŠ¸ í¬í•¨)")
    ai_answer = analyze_with_ai(user_message)
    if ai_answer:
        return ai_answer

    # 5. í´ë°±
    return "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•™êµë¡œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."

def create_kakao_response(message):
    return {
        "version": "2.0",
        "template": {
            "outputs": [
                {
                    "simpleText": {
                        "text": message
                    }
                }
            ]
        }
    }

@app.route('/webhook', methods=['POST'])
def webhook():
    try:
        data = request.get_json()
        user_message = data['userRequest']['utterance']
        
        # ìƒˆë¡œìš´ í•¸ë“¤ëŸ¬ í˜¸ì¶œ (ë§¥ë½ ì´í•´ ê°œì„ )
        response_text = handle_request(user_message)
        
        print(f"ì‚¬ìš©ì: '{user_message}' / ì±—ë´‡: '{response_text[:30]}...'")
        return jsonify(create_kakao_response(response_text))
        
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        # ì‚¬ìš©ìì—ê²ŒëŠ” ê°„ë‹¨í•œ ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œ
        return jsonify(create_kakao_response("ì‹œìŠ¤í…œì— ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ìš”ì²­ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."))

@app.route('/')
def home():
    return "íŒŒì£¼ì™€ì„ì´ˆë“±í•™êµ ì±—ë´‡ ì„œë²„ v2.2 (ë§¥ë½ ì´í•´ ê°œì„ )"

if __name__ == '__main__':
    init_db()
    app.run(debug=True, host='0.0.0.0', port=5000) 